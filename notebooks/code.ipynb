{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Optional\n",
    "from collections import OrderedDict\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import random_split, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"path/to/dir\", \n",
    "                 batch_size: int = 8, \n",
    "                 split: List[float] = [.7, .2, .1]):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.split = torch.tensor(split)\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        # check split\n",
    "        if len(self.split) != 3: raise Exception(\"split size should be 3 (train, val, test)\")\n",
    "        # normalize split\n",
    "        self.split = self.split / self.split.sum()\n",
    "\n",
    "        # using ImageFolder\n",
    "        food_images = datasets.ImageFolder(self.data_dir, self.transform)\n",
    "        self.classes = food_images.classes\n",
    "\n",
    "        # set dims\n",
    "        self.dims = tuple(food_images[0][0].shape)\n",
    "\n",
    "        # counts/splits\n",
    "        sz = len(food_images)\n",
    "        train_sz = math.floor(self.split[0] * sz)\n",
    "        val_sz = math.floor(self.split[1] * sz)\n",
    "        test_sz = sz - train_sz - val_sz\n",
    "\n",
    "        # split\n",
    "        self.train, self.val, self.test = random_split(food_images, [train_sz, val_sz, test_sz])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodModel(pl.LightningModule):\n",
    "    def __init__(self, classes: List[str], learning_rate: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.lr = learning_rate\n",
    "        self.classes = classes\n",
    "\n",
    "        # model layers\n",
    "        self.xfer = models.resnet18(pretrained=True)\n",
    "        self.fc1 = nn.Linear(1000, 256)\n",
    "        self.fc2 = nn.Linear(256, len(self.classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.xfer(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.softmax(self.fc2(x), dim=-1)\n",
    "\n",
    "    @staticmethod\n",
    "    def __accuracy(outputs, Y):\n",
    "        with torch.no_grad():\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            return (preds == Y).float().sum().item()\n",
    "\n",
    "    def __step(self, batch):\n",
    "        X, Y = batch\n",
    "        outputs = self(X)\n",
    "        loss = F.cross_entropy(outputs, Y)\n",
    "        return loss, self.__accuracy(outputs, Y)\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc = self.__step(batch)\n",
    "\n",
    "        tqdm_dict = {'train_loss': loss}\n",
    "        return OrderedDict({\n",
    "            'loss': loss,\n",
    "            'acc': acc\n",
    "        })\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc = self.__step(batch)\n",
    "\n",
    "        tqdm_dict = {'train_loss': loss}\n",
    "        return OrderedDict({\n",
    "            'val_loss': loss,\n",
    "            'val_acc': acc\n",
    "        })\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.SGD(\n",
    "            self.parameters(), \n",
    "            lr=self.lr\n",
    "        )\n",
    "        scheduler = optim.lr_scheduler.StepLR(\n",
    "            optimizer, \n",
    "            step_size=7, \n",
    "            gamma=0.1\n",
    "        )\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = FoodDataModule(data_dir='../data/food')\n",
    "dm.setup()\n",
    "model = FoodModel(classes=dm.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | xfer | ResNet | 11.7 M\n",
      "1 | fc1  | Linear | 256 K \n",
      "2 | fc2  | Linear | 514   \n",
      "--------------------------------\n",
      "11.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.9 M    Total params\n",
      "47.785    Total estimated model params size (MB)\n",
      "Epoch 0:  78%|███████▊  | 226/291 [01:22<00:23,  2.75it/s, loss=0.543, v_num=13]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/65 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  78%|███████▊  | 228/291 [01:22<00:22,  2.77it/s, loss=0.543, v_num=13]\n",
      "Validating:   3%|▎         | 2/65 [00:00<00:28,  2.18it/s]\u001b[A\n",
      "Validating:   5%|▍         | 3/65 [00:01<00:19,  3.11it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▉  | 231/291 [01:23<00:21,  2.77it/s, loss=0.543, v_num=13]\n",
      "Validating:   8%|▊         | 5/65 [00:01<00:22,  2.69it/s]\u001b[A\n",
      "Validating:   9%|▉         | 6/65 [00:01<00:18,  3.16it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 234/291 [01:24<00:20,  2.77it/s, loss=0.543, v_num=13]\n",
      "Validating:  12%|█▏        | 8/65 [00:02<00:17,  3.22it/s]\u001b[A\n",
      "Validating:  14%|█▍        | 9/65 [00:02<00:17,  3.28it/s]\u001b[A\n",
      "Epoch 0:  81%|████████▏ | 237/291 [01:25<00:19,  2.78it/s, loss=0.543, v_num=13]\n",
      "Validating:  17%|█▋        | 11/65 [00:03<00:12,  4.31it/s]\u001b[A\n",
      "Validating:  18%|█▊        | 12/65 [00:03<00:10,  4.90it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 240/291 [01:25<00:18,  2.80it/s, loss=0.543, v_num=13]\n",
      "Validating:  22%|██▏       | 14/65 [00:03<00:08,  6.10it/s]\u001b[A\n",
      "Validating:  23%|██▎       | 15/65 [00:03<00:07,  6.85it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▎ | 243/291 [01:26<00:17,  2.81it/s, loss=0.543, v_num=13]\n",
      "Validating:  26%|██▌       | 17/65 [00:04<00:13,  3.48it/s]\u001b[A\n",
      "Validating:  28%|██▊       | 18/65 [00:05<00:17,  2.75it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 246/291 [01:27<00:16,  2.81it/s, loss=0.543, v_num=13]\n",
      "Validating:  31%|███       | 20/65 [00:05<00:15,  2.89it/s]\u001b[A\n",
      "Validating:  32%|███▏      | 21/65 [00:06<00:13,  3.33it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 249/291 [01:28<00:14,  2.82it/s, loss=0.543, v_num=13]\n",
      "Validating:  35%|███▌      | 23/65 [00:06<00:10,  4.06it/s]\u001b[A\n",
      "Validating:  37%|███▋      | 24/65 [00:07<00:20,  1.98it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 252/291 [01:29<00:13,  2.80it/s, loss=0.543, v_num=13]\n",
      "Validating:  40%|████      | 26/65 [00:07<00:13,  2.84it/s]\u001b[A\n",
      "Validating:  42%|████▏     | 27/65 [00:08<00:11,  3.43it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 255/291 [01:30<00:12,  2.81it/s, loss=0.543, v_num=13]\n",
      "Validating:  45%|████▍     | 29/65 [00:09<00:14,  2.48it/s]\u001b[A\n",
      "Validating:  46%|████▌     | 30/65 [00:09<00:11,  2.92it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▊ | 258/291 [01:31<00:11,  2.82it/s, loss=0.543, v_num=13]\n",
      "Validating:  49%|████▉     | 32/65 [00:09<00:09,  3.39it/s]\u001b[A\n",
      "Validating:  51%|█████     | 33/65 [00:10<00:08,  3.77it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 261/291 [01:32<00:10,  2.83it/s, loss=0.543, v_num=13]\n",
      "Validating:  54%|█████▍    | 35/65 [00:11<00:14,  2.02it/s]\u001b[A\n",
      "Validating:  55%|█████▌    | 36/65 [00:11<00:13,  2.19it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 264/291 [01:33<00:09,  2.81it/s, loss=0.543, v_num=13]\n",
      "Validating:  58%|█████▊    | 38/65 [00:12<00:09,  2.72it/s]\u001b[A\n",
      "Validating:  60%|██████    | 39/65 [00:12<00:07,  3.31it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 267/291 [01:34<00:08,  2.82it/s, loss=0.543, v_num=13]C:\\Users\\sethj\\.conda\\envs\\torch\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:51: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  92%|█████████▏| 267/291 [01:35<00:08,  2.81it/s, loss=0.543, v_num=13]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1)\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}